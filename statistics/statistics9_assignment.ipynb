{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2be35e-4a4d-4fb3-a04d-0051ce96b23c",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34a28b-9678-4266-86a3-75ded4787f20",
   "metadata": {},
   "source": [
    "Ans= 1) Probability Mass Function (PMF): The PMF is used for discrete random variables. It assigns probabilities to individual values of the random variable. In other words, it describes the probability of each possible outcome.\n",
    "\n",
    "Example:\n",
    "Let's consider a fair six-sided die. The random variable is the outcome of rolling the die, which can take values from 1 to 6. The PMF for this random variable is a function that assigns probabilities to each possible outcome. Since the die is fair, the probability of rolling any particular number is 1/6. So, the PMF for this example would be:\n",
    "\n",
    "PMF(x) = 1/6 for x = 1, 2, 3, 4, 5, 6\n",
    "PMF(x) = 0 for any other value of x\n",
    "\n",
    "This means that the probability of rolling a 1, 2, 3, 4, 5, or 6 is all equal to 1/6, and the probability of rolling any other number is 0.\n",
    "\n",
    "2) Probability Density Function (PDF): The PDF is used for continuous random variables. Unlike the PMF, the PDF does not assign probabilities to individual values since continuous variables can take on an infinite number of values within a range. Instead, it provides the relative likelihood of the random variable falling within a certain interval.\n",
    "\n",
    "Example:\n",
    "Let's consider a continuous random variable, such as the height of adult males. The PDF describes the probability density of different heights occurring within a given range. Suppose the PDF of male heights follows a normal distribution with a mean of 180 cm and a standard deviation of 10 cm. The PDF function for this example would be:\n",
    "\n",
    "PDF(x) = (1 / (σ * √(2π))) * e^(-(x - μ)^2 / (2 * σ^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aced6a8-0694-4c87-bfc0-a92a27dc53e7",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4dccd-f55f-45f1-96a8-246edfa08d5f",
   "metadata": {},
   "source": [
    "Ans= The Cumulative Density Function (CDF) is a mathematical function that provides the cumulative probability distribution of a random variable. It gives the probability that the random variable takes on a value less than or equal to a given value.\n",
    "\n",
    "The CDF is used to understand the probability of a random variable falling within a specific range or being below a certain threshold. It can be used to calculate probabilities, percentiles, and quantiles.\n",
    "\n",
    "Example:\n",
    "Let's consider a random variable X that represents the number of heads obtained when flipping a fair coin twice. The possible values for X are 0, 1, and 2.\n",
    "\n",
    "The PMF for this random variable is as follows:\n",
    "\n",
    "PMF(X = 0) = 0.25\n",
    "\n",
    "PMF(X = 1) = 0.50\n",
    "\n",
    "PMF(X = 2) = 0.25\n",
    "\n",
    "To calculate the CDF, we determine the cumulative probabilities for each value of X. Starting from the smallest value, we add up the probabilities as we move to larger values.\n",
    "\n",
    "CDF(X = 0) = PMF(X = 0) = 0.25\n",
    "\n",
    "CDF(X = 1) = PMF(X = 0) + PMF(X = 1) = 0.25 + 0.50 = 0.75\n",
    "\n",
    "CDF(X = 2) = PMF(X = 0) + PMF(X = 1) + PMF(X = 2) = 0.25 + 0.50 + 0.25 = 1.00\n",
    "\n",
    "The CDF provides the cumulative probabilities for each value of X. In this example, the CDF(0) is 0.25, which means there is a 25% probability of obtaining 0 heads or fewer when flipping the coin twice. The CDF(1) is 0.75, indicating a 75% probability of getting 1 head or fewer. Finally, the CDF(2) is 1.00, representing a 100% probability of getting 2 heads or fewer.\n",
    "\n",
    "The CDF is useful because it provides a comprehensive picture of the probability distribution of a random variable. It allows us to analyze the likelihood of a random variable falling within certain intervals or being below specific thresholds. Additionally, it can be used to calculate percentiles, which help determine the value below which a certain percentage of the data falls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961e0e6-127b-4483-a0e3-b6f3b6fe420e",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bdf8b1-a787-430a-adde-e27415408447",
   "metadata": {},
   "source": [
    "Ans= Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1) Height of individuals: The heights of adult individuals tend to follow a normal distribution. The parameters of the normal distribution, such as the mean and standard deviation, can describe the average height and the variation around that average in a population.\n",
    "\n",
    "2) IQ scores: IQ scores are often assumed to follow a normal distribution. The mean and standard deviation of the normal distribution can provide information about the average intelligence level and the spread of IQ scores within a population.\n",
    "\n",
    "The parameters of the normal distribution relate to the shape of the distribution as:\n",
    "\n",
    "Mean (μ): The mean determines the central location or peak of the normal distribution. It represents the average or expected value of the variable being modeled. Shifting the mean to the left or right will result in the entire distribution shifting accordingly.\n",
    "\n",
    "Standard deviation (σ): The standard deviation controls the spread or dispersion of the normal distribution. A smaller standard deviation implies a narrower distribution with values concentrated closely around the mean. Conversely, a larger standard deviation leads to a wider distribution with values more spread out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedee75-5473-40d7-949f-6c83c2412b16",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9ae25-d95e-43c9-8ae4-530b7967e1ac",
   "metadata": {},
   "source": [
    "Ans= Importance of normal distribution\n",
    "\n",
    "1) It has one of the important properties called central theorem. Central theorem means relationship between shape of population distribution and shape of sampling distribution of mean. This means that sampling distribution of mean approaches normal as sample size increase.\n",
    "\n",
    "2) In case the sample size is large the normal distribution serves as good approximation.\n",
    "\n",
    "3) Due to its mathematical properties it is more popular and easy to calculate.\n",
    "\n",
    "4) It is used in statistical quality control in setting up of control limits.\n",
    "\n",
    "Examples:\n",
    "\n",
    "a) Human height: The height of adult individuals often follows a roughly normal distribution. While there may be variations in populations due to factors like gender and ethnicity, the overall distribution tends to resemble a bell curve.\n",
    "\n",
    "b) Exam scores: In large populations of students taking an exam, the distribution of scores can often be approximated by a normal distribution. This assumption allows for statistical analysis, such as calculating percentiles and identifying cutoff points for different performance categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93802af7-aaa3-4bdc-b6ae-70ee0a315232",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e807de-ab50-4a7a-9e8d-898164f8cd15",
   "metadata": {},
   "source": [
    "Ans= The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes, typically labeled as success (typically represented by 1) and failure (typically represented by 0).\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is as follows:\n",
    "\n",
    "PMF(x) = p^x * (1-p)^(1-x)\n",
    "\n",
    "where x is the outcome (0 or 1) and p is the probability of success.\n",
    "\n",
    "Example:\n",
    "Let's consider an example of flipping a fair coin. We can model this experiment using the Bernoulli distribution. Let's say we define getting heads as a success (1) and getting tails as a failure (0). The probability of getting heads is p = 0.5 since the coin is fair.\n",
    "\n",
    "The Bernoulli distribution for this coin flip experiment would be:\n",
    "PMF(x) = 0.5^x * 0.5^(1-x) = 0.5 for x = 0 or 1\n",
    "\n",
    "This means that the probability of getting heads (success) is 0.5, and the probability of getting tails (failure) is also 0.5.\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution:\n",
    "\n",
    "Bernoulli Distribution:\n",
    "\n",
    "Models a single trial with two possible outcomes (success or failure).\n",
    "Characterized by a single parameter, p, which represents the probability of success.\n",
    "The outcome is represented by a single random variable, typically taking values of 0 or 1.\n",
    "Binomial Distribution:\n",
    "\n",
    "Models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "Consists of multiple Bernoulli trials with the same probability of success, p.\n",
    "Characterized by two parameters: n (the number of trials) and p (the probability of success in each trial).\n",
    "The random variable in the binomial distribution represents the count or number of successes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79922261-5c7a-41b5-8d2d-474611410833",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ddb07-70b5-4d0a-bccd-315de308df7d",
   "metadata": {},
   "source": [
    "Ans= This involves transforming the values to a standard normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The formula to standardize a value is:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "Where:\n",
    "Z = Standardized value (z-score)\n",
    "\n",
    "X = Value from the dataset\n",
    "\n",
    "μ = Mean of the dataset\n",
    "\n",
    "σ = Standard deviation of the dataset\n",
    "\n",
    "In this case, we want to find the probability of a value greater than 60, so we need to standardize 60 using the mean and standard deviation provided:\n",
    "\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "\n",
    "Now, we need to find the probability associated with this standardized value using the standard normal distribution table or calculator. The table or calculator will provide the probability corresponding to the area under the curve to the right of the standardized value.\n",
    "\n",
    "The probability that a randomly selected observation will be greater than 60 can be found as follows:\n",
    "\n",
    "P(X > 60) = P(Z > 1)\n",
    "\n",
    "Using the standard normal distribution table or calculator, we find that the probability corresponding to Z = 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587, or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108d48d-e0a6-4607-8477-7505abb69525",
   "metadata": {},
   "source": [
    "## Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7cf80d-786a-4905-9c95-8d81687fb3a0",
   "metadata": {},
   "source": [
    "Ans= The uniform distribution is a probability distribution that describes a continuous random variable with a constant probability over a defined interval. In simple terms, it means that all values within the interval have an equal chance of occurring.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let's consider an example of rolling a fair six-sided die. The outcome of rolling the die can be any integer from 1 to 6, and each outcome has an equal probability of occurring. We can model this situation using a uniform distribution.\n",
    "\n",
    "For this example, the interval would be [1, 6], as it encompasses all possible outcomes of the die roll.\n",
    "\n",
    "The PDF of the uniform distribution for this example would be:\n",
    "\n",
    "PDF(x) = 1 / (6 - 1) = 1/5 for 1 ≤ x ≤ 6\n",
    "PDF(x) = 0 for x < 1 or x > 6\n",
    "\n",
    "This means that within the interval [1, 6], all values have an equal probability of occurring, which is 1/5 or 0.2.\n",
    "\n",
    "In the case of the die roll, any value between 1 and 6 has the same probability of occurring, with each value having a probability of 0.2 or 20%. The uniform distribution ensures that each possible outcome is equally likely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e79ff1-7881-43e3-bc91-b0a2a38fc40b",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90793162-3a36-4fb2-9b40-abeddfc864d7",
   "metadata": {},
   "source": [
    "Ans= The z-score, also known as the standard score, is a measure that indicates how many standard deviations a particular data point or observation is away from the mean of a distribution. It standardizes data by transforming it into a standard normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The formula to calculate the z-score for a data point x in a distribution with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The importance of the z-score are:\n",
    "\n",
    "1) Standardization and Comparison: The z-score enables us to standardize different datasets with varying means and standard deviations, making them comparable on a common scale. By calculating the z-score, we can determine how a particular observation relates to the distribution as a whole, regardless of the specific dataset.\n",
    "\n",
    "2) Probability Calculation: The z-score is useful for calculating probabilities associated with a given value or range in a normal distribution. By referring to a standard normal distribution table or using statistical software, we can determine the proportion of data points that fall below, above, or between specific z-scores. This is particularly helpful for hypothesis testing, confidence intervals, and determining critical values.\n",
    "\n",
    "3) Outlier Detection: The z-score is a valuable tool for identifying outliers in a dataset. Data points with z-scores significantly larger or smaller than the typical range indicate observations that deviate from the expected pattern. Outliers may indicate measurement errors, extreme values, or important insights about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd495c55-1764-439b-8e41-5c297f26cbf0",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6ca2f-bdee-4a56-b189-05b71a2c3ece",
   "metadata": {},
   "source": [
    "Ans= The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics. It states that when independent random variables are added together, their sum tends to follow a normal distribution, regardless of the shape of the original variables' distribution, as long as certain conditions are met.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "Approximation of Distributions: The Central Limit Theorem allows us to approximate the distribution of a sample mean or sum, even if the original population or individual variables do not follow a normal distribution. This is particularly valuable because the normal distribution is well-understood and mathematically tractable, making it easier to perform statistical inference and make probabilistic statements.\n",
    "\n",
    "Understanding Sampling Distributions: The Central Limit Theorem helps explain the properties of sampling distributions. It shows that as the sample size increases, the sampling distribution of the sample mean or sum becomes increasingly normal, regardless of the original population distribution. This insight is crucial in understanding the behavior of sample statistics and the reliability of estimates.\n",
    "\n",
    "Population Inference from Sample Data: The Central Limit Theorem provides a means to generalize findings from a sample to the population. By relying on the normal distribution approximation, we can draw conclusions about population parameters based on sample statistics, such as the mean or proportion, even when the population distribution is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95360b85-d1cc-42c4-94c1-fa638ed39b52",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96615825-ce13-4f25-8902-b617bbd5b367",
   "metadata": {},
   "source": [
    "Ans= The assumptions of the Central Limit Theorem include:\n",
    "\n",
    "1) Independent and Identically Distributed (IID) Random Variables: The random variables in the sequence X₁, X₂, ..., Xₙ should be independent of each other and have the same underlying distribution. Each random variable should have the same mean (μ) and standard deviation (σ).\n",
    "\n",
    "2) Finite Mean and Variance: The random variables should have finite means (E(X)) and finite variances (Var(X)). This assumption ensures that the mean and variance of the sum or average of the random variables are well-defined.\n",
    "\n",
    "3) Finite Sample Size: The CLT works best as the sample size (n) increases. While there is no strict requirement for a large sample size, the theorem typically applies more accurately as the sample size grows. However, even with smaller sample sizes, the CLT approximation can be reasonable depending on the shape of the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2d958-9df4-4606-9211-c2be934e3155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
